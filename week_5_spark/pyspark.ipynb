{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e70f428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c248c1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef24e298",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('FHVHV') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a300a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pyspark.version' from '/usr/local/Cellar/apache-spark/3.3.2/libexec/python/pyspark/version.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a087c8",
   "metadata": {},
   "source": [
    "# ======= Preparing dataset ==========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e204bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhvhv/fhvhv_tripdata_2021-06.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd94fe78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fhvhv_tripdata_2021-06.csv.gz pyspark.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74d7d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read with pandas for semiparsing the file\n",
    "df_pd = pd.read_csv('fhvhv_tripdata_2021-06.csv.gz', nrows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "305be1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0712fce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pd.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "824c38e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.createDataFrame(df_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7688834",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('fhvhv_tripdata_2021-06.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69b4b1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: string (nullable = true)\n",
      " |-- dropoff_datetime: string (nullable = true)\n",
      " |-- PULocationID: string (nullable = true)\n",
      " |-- DOLocationID: string (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c6bea4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('dispatching_base_num', StringType(), True), StructField('pickup_datetime', StringType(), True), StructField('dropoff_datetime', StringType(), True), StructField('PULocationID', StringType(), True), StructField('DOLocationID', StringType(), True), StructField('SR_Flag', StringType(), True), StructField('Affiliated_base_number', StringType(), True)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b247a7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType(\n",
    "    [\n",
    "        types.StructField(\"dispatching_base_num\", types.StringType(), True),\n",
    "        types.StructField(\"pickup_datetime\", types.TimestampType(), True),\n",
    "        types.StructField(\"dropoff_datetime\", types.TimestampType(), True),\n",
    "        types.StructField(\"PULocationID\", types.IntegerType(), True),\n",
    "        types.StructField(\"DOLocationID\", types.IntegerType(), True),\n",
    "        types.StructField(\"SR_Flag\", types.StringType(), True),\n",
    "        types.StructField(\"Affiliated_base_number\", types.StringType(), True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a475e4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema)\\\n",
    "    .csv('fhvhv_tripdata_2021-06.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "227548e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d12e2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "992199a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.parquet('fhvhv/2021/06/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6a91a4",
   "metadata": {},
   "source": [
    "# ========= Working with dataset ==========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee2b9960",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet('fhvhv/2021/06/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "552e73aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_hw = df.withColumn('pickup_date', F.date_trunc('DAY', df.pickup_datetime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "790a8ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+-------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|Affiliated_base_number|        pickup_date|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+-------------------+\n",
      "|              B02877|2021-06-11 12:28:02|2021-06-11 12:36:01|         230|          43|      N|                B02877|2021-06-11 00:00:00|\n",
      "|              B02765|2021-06-13 08:46:22|2021-06-13 09:03:00|          37|          61|      N|                B02765|2021-06-13 00:00:00|\n",
      "|              B02510|2021-06-28 18:39:27|2021-06-28 18:50:53|         231|          79|      N|                  null|2021-06-28 00:00:00|\n",
      "|              B02869|2021-06-05 18:15:05|2021-06-05 18:28:32|         244|         127|      N|                B02869|2021-06-05 00:00:00|\n",
      "|              B02872|2021-06-06 19:15:38|2021-06-06 19:26:58|          82|          82|      N|                B02872|2021-06-06 00:00:00|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_for_hw.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fbe93a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/apache-spark/3.3.2/libexec/python/pyspark/sql/dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df_for_hw.registerTempTable(\"fhvhv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa221d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|count(pickup_datetime)|\n",
      "+----------------------+\n",
      "|                452470|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "\"\"\"\n",
    "SELECT count(pickup_datetime)\n",
    "FROM fhvhv\n",
    "WHERE pickup_date = '2021-06-15 00:00:00'\n",
    "\n",
    "\"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5920c3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|            diff|\n",
      "+----------------+\n",
      "|66.8788888888889|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    max(((bigint(to_timestamp(dropoff_datetime)))-(bigint(to_timestamp(pickup_datetime))))/(3600)) as diff \n",
    "FROM fhvhv\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "607f2d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|            diff|\n",
      "+----------------+\n",
      "|66.8788888888889|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    max(((bigint(dropoff_datetime))-(bigint(pickup_datetime)))/(3600)) as diff \n",
    "FROM fhvhv\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "286d7cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|            diff|\n",
      "+----------------+\n",
      "|66.8788888888889|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    bigint(max(dropoff_datetime - pickup_datetime))/3600 as diff \n",
    "FROM fhvhv\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3ecc296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_zones = spark.read.option(\"header\", \"true\").csv('../taxi_zones.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "74e2844c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+--------------------+------------+\n",
      "|LocationID|Borough|                Zone|service_zone|\n",
      "+----------+-------+--------------------+------------+\n",
      "|         1|    EWR|      Newark Airport|         EWR|\n",
      "|         2| Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|  Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "+----------+-------+--------------------+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_zones.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b90dffc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_zones.registerTempTable(\"taxi_zones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7e14f073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+\n",
      "|               Zone| count|\n",
      "+-------------------+------+\n",
      "|Crown Heights North|231279|\n",
      "|       East Village|221244|\n",
      "|        JFK Airport|188867|\n",
      "|     Bushwick South|187929|\n",
      "|      East New York|186780|\n",
      "+-------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    Zone,\n",
    "    count(1) AS count\n",
    "FROM fhvhv\n",
    "JOIN taxi_zones on fhvhv.PULocationID = taxi_zones.LocationID\n",
    "GROUP BY Zone\n",
    "ORDER BY 2 DESC\n",
    "LIMIT 5\n",
    "\"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
